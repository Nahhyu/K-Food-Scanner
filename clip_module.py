import torch
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import streamlit as st

# ğŸ”¥ config ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
from config import (
    MODEL_PATH,
    DEVICE,
    NORMALIZE_EMBEDDINGS,
)


# ============================================
# 1) Fine-tuned CLIP ëª¨ë¸ ë¡œë“œ (Streamlit ìºì‹œ)
# ============================================

@st.cache_resource
def load_clip_model():
    """
    Fine-tuned(LoRA merge) CLIP ëª¨ë¸ì„ ë¡œë“œí•´ì„œ ë°˜í™˜í•œë‹¤.
    Streamlit ìºì‹œë¡œ í•œ ë²ˆë§Œ ë¡œë“œë¨.
    """
    model = CLIPModel.from_pretrained(MODEL_PATH)
    processor = CLIPProcessor.from_pretrained(MODEL_PATH)
    model.to(DEVICE)
    model.eval()
    return processor, model


processor, model = load_clip_model()


# ============================================
# 2) ì´ë¯¸ì§€ â†’ ìŒì‹ ë¼ë²¨ ì˜ˆì¸¡ í•¨ìˆ˜
# ============================================

def predict_food(image: Image.Image, candidate_foods: list[str]) -> str:
    """
    Fine-tuned CLIPì„ ì´ìš©í•´ ì´ë¯¸ì§€ì™€ ê°€ì¥ ìœ ì‚¬í•œ ìŒì‹ ë ˆì´ë¸”ì„ ì„ íƒí•œë‹¤.
    - image: PIL Image
    - candidate_foods: ["kimbap", "bibimbap", "tteokbokki", ...]
    """

    if not candidate_foods:
        raise ValueError("Food í›„ë³´ ë ˆì´ë¸”ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # ------ 1. ì´ë¯¸ì§€ ì„ë² ë”© ------
    image_inputs = processor(images=image, return_tensors="pt").to(DEVICE)

    with torch.no_grad():
        image_features = model.get_image_features(**image_inputs)

    # ì •ê·œí™” ON/OFFëŠ” configì—ì„œ ì„¤ì •
    if NORMALIZE_EMBEDDINGS:
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)

    # ------ 2. í…ìŠ¤íŠ¸ ì„ë² ë”© ------
    text_inputs = processor(
        text=candidate_foods,
        return_tensors="pt",
        padding=True
    ).to(DEVICE)

    with torch.no_grad():
        text_features = model.get_text_features(**text_inputs)

    if NORMALIZE_EMBEDDINGS:
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)

    # ------ 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ------
    similarities = image_features @ text_features.T  # shape: (1, N)
    pred_idx = similarities.argmax(dim=-1).item()

    return candidate_foods[pred_idx]
